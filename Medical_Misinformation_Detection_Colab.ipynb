{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Misinformation Detection - Google Colab\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. Upload this notebook to Google Colab\n",
        "2. Upload your project files (see Step 2)\n",
        "3. Enable GPU: Runtime → Change runtime type → GPU\n",
        "4. Run all cells in order\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. Download data\n",
        "2. Process and label data\n",
        "3. Train all models (ML, DL, Transformer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q pandas numpy requests beautifulsoup4 scikit-learn matplotlib seaborn torch transformers datasets tqdm kaggle\n",
        "\n",
        "# Verify GPU availability\n",
        "import torch\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"GPU not detected. Enable GPU in Runtime → Change runtime type\")\n",
        "    print(\"Training will be slower on CPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Project Files\n",
        "\n",
        "Upload a ZIP or RAR file containing:\n",
        "- `data_downloader.py`\n",
        "- `process_and_label_data.py`\n",
        "- `train_all_models.py`\n",
        "- `utils/` folder\n",
        "- `api_keys.py` (optional, for Kaggle API)\n",
        "- `disease_symptoms.csv` (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Upload Project File (ZIP or RAR)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "extracted = False\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nProcessing {filename}...\")\n",
        "    \n",
        "    if filename.endswith('.zip'):\n",
        "        print(\"Extracting ZIP file...\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall('.')\n",
        "            print(\"ZIP extraction complete\")\n",
        "            extracted = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting ZIP: {e}\")\n",
        "    \n",
        "    elif filename.endswith('.rar'):\n",
        "        print(\"Extracting RAR file...\")\n",
        "        try:\n",
        "            subprocess.run(['apt-get', 'update'], check=False, capture_output=True)\n",
        "            subprocess.run(['apt-get', 'install', '-y', 'unrar'], check=False, capture_output=True)\n",
        "            \n",
        "            result = subprocess.run(['unrar', 'x', filename, '-y'], capture_output=True, text=True)\n",
        "            \n",
        "            if result.returncode == 0:\n",
        "                print(\"RAR extraction complete\")\n",
        "                extracted = True\n",
        "            else:\n",
        "                print(f\"Error extracting RAR: {result.stderr[:200]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"Unknown file type: {filename}\")\n",
        "\n",
        "if not extracted:\n",
        "    print(\"\\nNo files were extracted. Check your file format.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Looking for project files...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    current_files = os.listdir('.')\n",
        "    print(f\"Files in current directory: {len(current_files)} items\")\n",
        "except Exception as e:\n",
        "    print(f\"Error listing directory: {e}\")\n",
        "    current_files = []\n",
        "\n",
        "required_files = ['data_downloader.py', 'process_and_label_data.py', 'train_all_models.py']\n",
        "found_files = [f for f in required_files if os.path.exists(f)]\n",
        "\n",
        "if len(found_files) == len(required_files):\n",
        "    print(\"All required files found in current directory\")\n",
        "    print(f\"Current directory: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"Required files not in current directory\")\n",
        "    print(f\"Found: {found_files}\")\n",
        "    print(f\"Missing: {[f for f in required_files if f not in found_files]}\")\n",
        "    print(\"\\nSearching for project directory...\")\n",
        "    \n",
        "    possible_dirs = [\n",
        "        'Medical Misinformation Detection',\n",
        "        'Medical_Misinformation_Detection',\n",
        "        'medical-misinformation-detection'\n",
        "    ]\n",
        "    \n",
        "    found_dir = None\n",
        "    for root, dirs, files_list in os.walk('.'):\n",
        "        if all(f in files_list for f in required_files):\n",
        "            found_dir = root\n",
        "            print(f\"Found project directory: {root}\")\n",
        "            break\n",
        "    \n",
        "    if not found_dir:\n",
        "        for dir_name in possible_dirs:\n",
        "            if os.path.exists(dir_name):\n",
        "                if all(os.path.exists(os.path.join(dir_name, f)) for f in required_files):\n",
        "                    found_dir = dir_name\n",
        "                    print(f\"Found project directory: {dir_name}\")\n",
        "                    break\n",
        "    \n",
        "    if found_dir:\n",
        "        if found_dir != '.':\n",
        "            os.chdir(found_dir)\n",
        "        print(f\"\\nChanged to project directory: {found_dir}\")\n",
        "        print(f\"Current directory: {os.getcwd()}\")\n",
        "        found_files = [f for f in required_files if os.path.exists(f)]\n",
        "        if len(found_files) == len(required_files):\n",
        "            print(\"All required files now found\")\n",
        "    else:\n",
        "        print(\"\\nProject directory not found automatically.\")\n",
        "        print(\"Check the file browser on the left\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Final File Check\")\n",
        "print(\"=\" * 60)\n",
        "for file in required_files:\n",
        "    if os.path.exists(file):\n",
        "        size = os.path.getsize(file)\n",
        "        print(f\"{file} ({size:,} bytes)\")\n",
        "    else:\n",
        "        print(f\"{file} - MISSING\")\n",
        "        for root, dirs, files_list in os.walk('.'):\n",
        "            if file in files_list:\n",
        "                print(f\"  Found at: {os.path.join(root, file)}\")\n",
        "\n",
        "if os.path.exists('utils'):\n",
        "    utils_files = os.listdir('utils')\n",
        "    print(f\"utils/ folder found ({len(utils_files)} files)\")\n",
        "else:\n",
        "    print(\"utils/ folder - MISSING\")\n",
        "    for root, dirs, files_list in os.walk('.'):\n",
        "        if 'utils' in dirs:\n",
        "            utils_path = os.path.join(root, 'utils')\n",
        "            print(f\"  Found utils at: {utils_path}\")\n",
        "\n",
        "if os.path.exists('api_keys.py'):\n",
        "    print(f\"\\napi_keys.py found\")\n",
        "else:\n",
        "    print(f\"\\napi_keys.py not found (optional)\")\n",
        "\n",
        "print(f\"\\nCurrent working directory: {os.getcwd()}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1b: Setup Kaggle API\n",
        "\n",
        "Reads Kaggle credentials from `api_keys.py` if included in Step 2. Skip if not using Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Kaggle API Setup\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kaggle_configured = False\n",
        "\n",
        "if os.path.exists('api_keys.py'):\n",
        "    print(\"\\nFound api_keys.py - checking for Kaggle credentials...\")\n",
        "    try:\n",
        "        with open('api_keys.py', 'r') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        username = None\n",
        "        key = None\n",
        "        \n",
        "        for line in content.split('\\n'):\n",
        "            if 'KAGGLE_USERNAME' in line and '=' in line:\n",
        "                username = line.split('=')[1].strip().strip('\"').strip(\"'\").strip()\n",
        "            elif 'KAGGLE_KEY' in line and '=' in line:\n",
        "                key = line.split('=')[1].strip().strip('\"').strip(\"'\").strip()\n",
        "        \n",
        "        if username and key:\n",
        "            print(f\"Found Kaggle credentials\")\n",
        "            print(f\"Username: {username}\")\n",
        "            \n",
        "            os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "            kaggle_config = {\n",
        "                \"username\": username,\n",
        "                \"key\": key\n",
        "            }\n",
        "            \n",
        "            with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "                json.dump(kaggle_config, f)\n",
        "            \n",
        "            os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "            os.chmod('/root/.kaggle', 700)\n",
        "            \n",
        "            print(\"Kaggle API configured from api_keys.py\")\n",
        "            kaggle_configured = True\n",
        "        else:\n",
        "            print(\"api_keys.py found but Kaggle credentials not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading api_keys.py: {e}\")\n",
        "else:\n",
        "    print(\"api_keys.py not found\")\n",
        "\n",
        "if not kaggle_configured:\n",
        "    print(\"\\nAlternative: Upload kaggle.json file directly\")\n",
        "    print(\"Get kaggle.json from: https://www.kaggle.com/account\\n\")\n",
        "    \n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        \n",
        "        for filename in uploaded.keys():\n",
        "            if filename == 'kaggle.json':\n",
        "                os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "                os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "                os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "                os.chmod('/root/.kaggle', 700)\n",
        "                \n",
        "                print(\"Kaggle API configured from uploaded file\")\n",
        "                kaggle_configured = True\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(f\"Upload skipped: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if kaggle_configured:\n",
        "    print(\"Kaggle API Configured\")\n",
        "    print(\"Kaggle datasets will be downloaded in Step 4\")\n",
        "else:\n",
        "    print(\"Kaggle API Not Configured\")\n",
        "    print(\"Kaggle datasets will be skipped\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Download Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"data_downloader.py exists: {os.path.exists('data_downloader.py')}\\n\")\n",
        "\n",
        "kaggle_config = os.path.expanduser('~/.kaggle/kaggle.json')\n",
        "if os.path.exists(kaggle_config):\n",
        "    print(\"Kaggle API is configured\")\n",
        "else:\n",
        "    print(\"Kaggle API not configured - Kaggle datasets will be skipped\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting Data Download\")\n",
        "print(\"=\" * 60)\n",
        "!python data_downloader.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Process and Label Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Checking Available Data\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "raw_data_path = 'data/processed/raw_downloaded_data.csv'\n",
        "if os.path.exists(raw_data_path):\n",
        "    size = os.path.getsize(raw_data_path)\n",
        "    print(f\"Raw data found: {size:,} bytes\")\n",
        "else:\n",
        "    print(\"Raw data file not found\")\n",
        "\n",
        "data_dir = 'general_medical_misinformation_data'\n",
        "if os.path.exists(data_dir):\n",
        "    files = []\n",
        "    for root, dirs, file_list in os.walk(data_dir):\n",
        "        files.extend([os.path.join(root, f) for f in file_list])\n",
        "    print(f\"Found {len(files)} files in download directory\")\n",
        "else:\n",
        "    print(\"Download directory not found\")\n",
        "\n",
        "processed_path = 'data/processed/medical_dataset.csv'\n",
        "if os.path.exists(processed_path):\n",
        "    size = os.path.getsize(processed_path)\n",
        "    print(f\"Existing processed dataset found: {size:,} bytes\")\n",
        "else:\n",
        "    print(\"No existing processed dataset\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting Data Processing and Labeling\")\n",
        "print(\"=\" * 60)\n",
        "!python process_and_label_data.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Train All Models\n",
        "\n",
        "Trains ML models (Logistic Regression, Random Forest), DL models (CNN, LSTM), and Transformer (BioBERT).\n",
        "\n",
        "May take 1-3 hours depending on dataset size and GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "dataset_path = 'data/processed/medical_dataset.csv'\n",
        "if os.path.exists(dataset_path):\n",
        "    print(f\"Found dataset: {dataset_path}\")\n",
        "    try:\n",
        "        df_sample = pd.read_csv(dataset_path, nrows=5)\n",
        "        print(f\"Dataset columns: {list(df_sample.columns)}\")\n",
        "        full_df = pd.read_csv(dataset_path)\n",
        "        print(f\"Total rows: {len(full_df):,}\")\n",
        "        if len(full_df) == 0:\n",
        "            print(\"ERROR: Dataset is empty\")\n",
        "            raise ValueError(\"Dataset is empty\")\n",
        "        print(\"Label distribution:\")\n",
        "        label_counts = full_df['label'].value_counts()\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"  {label}: {count:,}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading dataset: {e}\")\n",
        "        raise\n",
        "else:\n",
        "    print(f\"ERROR: Dataset not found: {dataset_path}\")\n",
        "    raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting Model Training\")\n",
        "print(\"=\" * 60)\n",
        "!python train_all_models.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Verifying All Models and Results\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "required_models = {\n",
        "    'ML Models (2)': [\n",
        "        'models/ml/logistic_regression.pkl',\n",
        "        'models/ml/random_forest.pkl',\n",
        "        'models/ml/tfidf_vectorizer.pkl',\n",
        "        'models/ml/label_encoder.pkl'\n",
        "    ],\n",
        "    'DL Models (2)': [\n",
        "        'models/dl/cnn_best.pt',\n",
        "        'models/dl/lstm_best.pt'\n",
        "    ],\n",
        "    'Transformer Model (1)': [\n",
        "        'models/transformer/biobert_final/config.json'\n",
        "    ]\n",
        "}\n",
        "\n",
        "required_results = {\n",
        "    'ML Results': [\n",
        "        'results/ml/logistic_regression_metrics.json',\n",
        "        'results/ml/logistic_regression_confusion_matrix.png',\n",
        "        'results/ml/random_forest_metrics.json',\n",
        "        'results/ml/random_forest_confusion_matrix.png'\n",
        "    ],\n",
        "    'DL Results': [\n",
        "        'results/dl/cnn_metrics.json',\n",
        "        'results/dl/cnn_confusion_matrix.png',\n",
        "        'results/dl/cnn_curves.png',\n",
        "        'results/dl/lstm_metrics.json',\n",
        "        'results/dl/lstm_confusion_matrix.png',\n",
        "        'results/dl/lstm_curves.png'\n",
        "    ],\n",
        "    'Transformer Results': [\n",
        "        'results/transformer/biobert_metrics.json',\n",
        "        'results/transformer/biobert_confusion_matrix.png'\n",
        "    ]\n",
        "}\n",
        "\n",
        "missing_items = []\n",
        "found_items = []\n",
        "\n",
        "print(\"\\nChecking Models:\")\n",
        "for category, files_list in required_models.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for file_path in files_list:\n",
        "        if os.path.exists(file_path):\n",
        "            size = os.path.getsize(file_path)\n",
        "            print(f\"  ✓ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
        "            found_items.append(file_path)\n",
        "        else:\n",
        "            print(f\"  ✗ {os.path.basename(file_path)} - MISSING\")\n",
        "            missing_items.append(file_path)\n",
        "    \n",
        "    if category == 'Transformer Model (1)':\n",
        "        transformer_dir = 'models/transformer/biobert_final'\n",
        "        if os.path.exists(transformer_dir):\n",
        "            transformer_files = os.listdir(transformer_dir)\n",
        "            model_file = None\n",
        "            for f in transformer_files:\n",
        "                if f.endswith('.safetensors') or f.endswith('.bin'):\n",
        "                    model_file = os.path.join(transformer_dir, f)\n",
        "                    break\n",
        "            if model_file and os.path.exists(model_file):\n",
        "                size = os.path.getsize(model_file)\n",
        "                print(f\"  ✓ {os.path.basename(model_file)} ({size:,} bytes)\")\n",
        "                found_items.append(model_file)\n",
        "            else:\n",
        "                print(f\"  ✗ Transformer model weights file - MISSING\")\n",
        "                if not model_file:\n",
        "                    missing_items.append('models/transformer/biobert_final/model.safetensors or pytorch_model.bin')\n",
        "\n",
        "print(\"\\nChecking Results:\")\n",
        "for category, files_list in required_results.items():\n",
        "    print(f\"\\n{category}:\")\n",
        "    for file_path in files_list:\n",
        "        if os.path.exists(file_path):\n",
        "            size = os.path.getsize(file_path)\n",
        "            print(f\"  ✓ {os.path.basename(file_path)} ({size:,} bytes)\")\n",
        "            found_items.append(file_path)\n",
        "        else:\n",
        "            print(f\"  ✗ {os.path.basename(file_path)} - MISSING\")\n",
        "            missing_items.append(file_path)\n",
        "\n",
        "if missing_items:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"WARNING: Some files are missing!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Missing {len(missing_items)} file(s):\")\n",
        "    for item in missing_items:\n",
        "        print(f\"  - {item}\")\n",
        "    print(\"\\nThe ZIP will be created with available files only.\")\n",
        "else:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"All Required Models and Results Found!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✓ 2 ML Models (Logistic Regression, Random Forest)\")\n",
        "    print(\"✓ 2 DL Models (CNN, LSTM)\")\n",
        "    print(\"✓ 1 Transformer Model (BioBERT)\")\n",
        "    print(\"✓ All Results Files\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Creating ZIP Archive\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "zip_filename = f'medical_misinfo_results_{timestamp}.zip'\n",
        "\n",
        "files_added = 0\n",
        "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    if os.path.exists('models'):\n",
        "        for root, dirs, file_list in os.walk('models'):\n",
        "            for file in file_list:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path)\n",
        "                files_added += 1\n",
        "    \n",
        "    if os.path.exists('results'):\n",
        "        for root, dirs, file_list in os.walk('results'):\n",
        "            for file in file_list:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path)\n",
        "                files_added += 1\n",
        "    \n",
        "    if os.path.exists('data/processed/medical_dataset.csv'):\n",
        "        zipf.write('data/processed/medical_dataset.csv')\n",
        "        files_added += 1\n",
        "\n",
        "zip_size = os.path.getsize(zip_filename) / (1024 * 1024)\n",
        "print(f\"\\nCreated {zip_filename}\")\n",
        "print(f\"Total files: {files_added}\")\n",
        "print(f\"Archive size: {zip_size:.2f} MB\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Starting Download\")\n",
        "print(\"=\" * 60)\n",
        "files.download(zip_filename)\n",
        "print(\"\\nDownload initiated. Check your browser's download folder.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Save Outputs to Google Drive\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 7: Save Outputs to Google Drive\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "output_dir = '/content/drive/MyDrive/Medical_Misinformation_Project'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Copy folders and key files\n",
        "!cp -r models \"/content/drive/MyDrive/Medical_Misinformation_Project/\"\n",
        "!cp -r results \"/content/drive/MyDrive/Medical_Misinformation_Project/\"\n",
        "!cp data/processed/medical_dataset.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\"\n",
        "!cp data/processed/top_myths.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\" || true\n",
        "!cp data/processed/top_facts.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\" || true\n",
        "!cp data/processed/qa_pairs_100.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\" || true\n",
        "!cp data/processed/rag_vs_nonrag_comparison.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\" || true\n",
        "!cp data/processed/rag_vs_nonrag_detailed.csv \"/content/drive/MyDrive/Medical_Misinformation_Project/\" || true\n",
        "\n",
        "print(\"\\nFiles saved to Google Drive -> Medical_Misinformation_Project\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: RAG vs Non-RAG Evaluation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Step 8: RAG vs Non-RAG Evaluation\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "qa_path = 'data/processed/qa_pairs_100.csv'\n",
        "kb_path = 'data/processed/medical_dataset.csv'\n",
        "\n",
        "if not os.path.exists(qa_path) or not os.path.exists(kb_path):\n",
        "    raise FileNotFoundError(\"QA pairs or medical_dataset.csv not found. Run Steps 4-5 first.\")\n",
        "\n",
        "qa_df = pd.read_csv(qa_path)\n",
        "kb_df = pd.read_csv(kb_path)\n",
        "credible_texts = kb_df[kb_df['label'] == 'credible']['text'].dropna().tolist()\n",
        "if len(credible_texts) > 20000:\n",
        "    credible_texts = credible_texts[:20000]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
        "kb_matrix = vectorizer.fit_transform(credible_texts)\n",
        "\n",
        "harmful_terms = ['drink bleach', 'poison', 'dangerous advice', 'no treatment needed']\n",
        "\n",
        "\n",
        "def rag_answer(question, top_k=3):\n",
        "    q_vec = vectorizer.transform([question])\n",
        "    sims = cosine_similarity(q_vec, kb_matrix)[0]\n",
        "    top_idx = sims.argsort()[-top_k:][::-1]\n",
        "    retrieved = [credible_texts[i] for i in top_idx]\n",
        "    answer = \" \".join(retrieved)\n",
        "    return answer, retrieved\n",
        "\n",
        "\n",
        "def baseline_answer(question):\n",
        "    answer = (\"Further medical evaluation is required. Consult verified health sources \"\n",
        "              \"such as WHO/CDC for precise guidance.\")\n",
        "    return answer, []\n",
        "\n",
        "\n",
        "def evaluate_answer(pred, reference, retrieved):\n",
        "    tokens_pred = set(pred.lower().split())\n",
        "    tokens_ref = set(str(reference).lower().split())\n",
        "    overlap = tokens_pred & tokens_ref\n",
        "    precision = len(overlap) / (len(tokens_pred) + 1e-6)\n",
        "    recall = len(overlap) / (len(tokens_ref) + 1e-6)\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-6)\n",
        "    factuality = f1\n",
        "    completeness = recall\n",
        "    if retrieved:\n",
        "        ref_vec = vectorizer.transform([' '.join(retrieved)])\n",
        "        pred_vec = vectorizer.transform([pred])\n",
        "        faithfulness = float(cosine_similarity(ref_vec, pred_vec)[0][0])\n",
        "    else:\n",
        "        faithfulness = 0.0\n",
        "    safety = 0 if any(term in pred.lower() for term in harmful_terms) else 1\n",
        "    return {\n",
        "        'factuality': factuality,\n",
        "        'completeness': completeness,\n",
        "        'faithfulness': min(1.0, faithfulness),\n",
        "        'safety': safety\n",
        "    }\n",
        "\n",
        "rag_scores = []\n",
        "baseline_scores = []\n",
        "subset = qa_df.head(50)\n",
        "\n",
        "for _, row in subset.iterrows():\n",
        "    question = row['question']\n",
        "    reference = row.get('answer', '')\n",
        "    rag_pred, retrieved = rag_answer(question)\n",
        "    baseline_pred, _ = baseline_answer(question)\n",
        "    rag_scores.append(evaluate_answer(rag_pred, reference, retrieved))\n",
        "    baseline_scores.append(evaluate_answer(baseline_pred, reference, []))\n",
        "\n",
        "rag_avg = {k: np.mean([score[k] for score in rag_scores]) for k in rag_scores[0]}\n",
        "baseline_avg = {k: np.mean([score[k] for score in baseline_scores]) for k in baseline_scores[0]}\n",
        "\n",
        "print(\"RAG Metrics (averaged over sample):\")\n",
        "for metric, value in rag_avg.items():\n",
        "    print(f\"  {metric.title()}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nNon-RAG Baseline Metrics (averaged over sample):\")\n",
        "for metric, value in baseline_avg.items():\n",
        "    print(f\"  {metric.title()}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Saving Comparison Results\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save summary comparison\n",
        "comparison_data = {\n",
        "    'Model': ['RAG', 'Non-RAG (Baseline)'],\n",
        "    'Factuality': [rag_avg['factuality'], baseline_avg['factuality']],\n",
        "    'Completeness': [rag_avg['completeness'], baseline_avg['completeness']],\n",
        "    'Faithfulness': [rag_avg['faithfulness'], baseline_avg['faithfulness']],\n",
        "    'Safety': [rag_avg['safety'], baseline_avg['safety']]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_path = 'data/processed/rag_vs_nonrag_comparison.csv'\n",
        "comparison_df.to_csv(comparison_path, index=False)\n",
        "print(f\"✓ Saved summary comparison to {comparison_path}\")\n",
        "\n",
        "# Save detailed results for each QA pair\n",
        "detailed_results = []\n",
        "for idx, row in subset.iterrows():\n",
        "    question = row['question']\n",
        "    reference = row.get('answer', '')\n",
        "    \n",
        "    rag_pred, retrieved = rag_answer(question)\n",
        "    baseline_pred, _ = baseline_answer(question)\n",
        "    \n",
        "    rag_scores = evaluate_answer(rag_pred, reference, retrieved)\n",
        "    baseline_scores = evaluate_answer(baseline_pred, reference, [])\n",
        "    \n",
        "    detailed_results.append({\n",
        "        'question': question,\n",
        "        'reference_answer': reference,\n",
        "        'rag_answer': rag_pred,\n",
        "        'rag_factuality': rag_scores['factuality'],\n",
        "        'rag_completeness': rag_scores['completeness'],\n",
        "        'rag_faithfulness': rag_scores['faithfulness'],\n",
        "        'rag_safety': rag_scores['safety'],\n",
        "        'nonrag_answer': baseline_pred,\n",
        "        'nonrag_factuality': baseline_scores['factuality'],\n",
        "        'nonrag_completeness': baseline_scores['completeness'],\n",
        "        'nonrag_faithfulness': baseline_scores['faithfulness'],\n",
        "        'nonrag_safety': baseline_scores['safety']\n",
        "    })\n",
        "\n",
        "detailed_df = pd.DataFrame(detailed_results)\n",
        "detailed_path = 'data/processed/rag_vs_nonrag_detailed.csv'\n",
        "detailed_df.to_csv(detailed_path, index=False)\n",
        "print(f\"✓ Saved detailed results for {len(detailed_df)} QA pairs to {detailed_path}\")\n",
        "\n",
        "# Copy to Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    output_dir = '/content/drive/MyDrive/Medical_Misinformation_Project'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    for file in ['rag_vs_nonrag_comparison.csv', 'rag_vs_nonrag_detailed.csv']:\n",
        "        src = f'data/processed/{file}'\n",
        "        if os.path.exists(src):\n",
        "            dst = os.path.join(output_dir, file)\n",
        "            shutil.copy2(src, dst)\n",
        "            print(f\"✓ Copied {file} to Google Drive\")\n",
        "    \n",
        "    print(f\"\\nAll RAG vs Non-RAG results saved to Google Drive -> Medical_Misinformation_Project\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not copy to Google Drive ({e})\")\n",
        "    print(\"Files are saved locally in data/processed/\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RAG vs Non-RAG Evaluation Complete\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Files created:\")\n",
        "print(\"  - rag_vs_nonrag_comparison.csv (summary metrics)\")\n",
        "print(\"  - rag_vs_nonrag_detailed.csv (per-QA pair results)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
